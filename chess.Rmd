---
title: "R Notebook"
output: pdf_document
---

```{r}
library(DBI)
library(gPdtest) # pareto

to_numeric <- function(list){
  return (as.numeric(unlist(list)))
}

pprint<-function(...){
     print(paste(...))
}

printf<-function(txt, ...){
  cat(sprintf(txt, ...), "\n")
}
```

\section{Wczytywanie danych}
W nowo stworzonej kolumnie z czasami gier odrzucona zostaje część wyników ze względu na niską dokładność zapisanych czasów rozpoczęcia i zakończenia gier.
```{r}
con <- dbConnect(RSQLite::SQLite(), ":memory:")
chess <- read.csv(file="./games.csv", header=TRUE, sep=",")
df <- data.frame(chess) 
dbWriteTable(con, "chess", df)


res <- dbSendQuery(con, "ALTER TABLE chess ADD time int")
res <- dbSendQuery(con, "UPDATE chess
                  SET time= CASE WHEN last_move_at - created_at=0 OR last_move_at - created_at=10000000
                            then NULL
                            ELSE last_move_at - created_at
                            END
                  ")
df <- dbReadTable(con, "chess")
res <- dbSendQuery(con, "DROP TABLE chess")

idx_all = c(0:11)
idx_drop = c(2, 3, 7)
dbWriteTable(con, "chess", df[!(idx_all %in% idx_drop)])

dbReadTable(con, "chess")
```

\section{Analiza czasu gry}
```{r}
MINUTE = 100*60
HOUR = MINUTE*60
DAY = HOUR*24

res <- dbGetQuery(con, "SELECT time, (white_rating + black_rating)/2 as rating, victory_status as result  FROM chess WHERE time is not null")
min_time = to_numeric(res["time"]/MINUTE)
GAMES_NUM = length(res$time)
                      
hist(min_time, xlim=c(0, 500), ylim=c(0,300), nclass =30000, xlab="czas (min.)", ylab="liczba gier", main="")

w = boxplot(min_time, ylim=c(0,1000), ylab="czas (min.)")$stats[5]

printf("Ilość wartości odstających (gry dłuższe niż %.1f godziny): %.1f%%", w/60,100*sum(min_time > w)/GAMES_NUM)
printf("Średni czas gry: %.2f min. \nmediana: %.2f min. \nkwantyle (dolny i górny): %.2f min.  %.2f min.", mean(min_time), median(min_time), quantile(min_time)[2], quantile(min_time)[4])
printf("Ilość gier dłużych niż jeden dzień: %.2f%%", 100*sum(res$time/DAY > 1)/GAMES_NUM)
printf("Ilość gier krótszych niż 6 godziny: %.2f%%", 100*sum(res$time/HOUR < 6)/GAMES_NUM)
printf("Najdłuższa gra trwała %.f dni", max(res$time)/DAY)
```
Dane zawierają znaczącą ilość wartości odstających (oddalonych od kwantyla górnego o ponad 1.5 odległości międzykwartyłowej). Odzwierciedla to dostępne tryby gry:\newline
-korespondencyjny\newline
-w czasie rzeczywistym\newline
Szacowany czas po którym gry w drugim trybie powinny się zakończyć to 6 godzin (co wynika z ogarniczeń narzucach na stronie i liczby tur po jakich kończy się przeciętna gra (60)) i rzeczywiście w tym czasie kończy się ponad 94% gier.\newline\newline


```{r}
plot(res$rating, res$time, ylim=c(0,4e6))
cor(res$time, res$rating)
```
Czas gry jest całkowicie nieskorelowany ze średnim poziomem graczy (który jest zbliżony do poziomu każdego z graczy - jak pokazano wcześniej).


```{r}
hour_time = res$time/HOUR
barplot(table(res$result[hour_time<6])/sum(hour_time<6), main="gry poniżej 6 godzin", ylab="% gier", xlab="wynik", ylim=c(0,0.6))
barplot(table(res$result[hour_time>6])/sum(hour_time>6), main="gry powyżej 6 godzin", ylab="% gier", xlab="wynik", ylim=c(0,0.6))
```
Wykresy pozwalają zauważyć, że przeciągające się gry zdecydowanie rzadziej kończą się matem niż gry krótsze, a gracze częściej remisują lub jednemu z nich kończy się czas. \newline
Rezygnacja z dalszej gry praktycznie nie zależy od czasu.



\section{Analiza otwarć}
kod ECO - kod przypisywany otwarciom szachowym\newline
$H_0$: częstość rozgrywania otwarcia jest rozłożona zgonie z rozkładem Pareto\newline
$H_1$: zmienna ta jest rozłożona według innego rozkładu\newline
przyjęty poziom istotności: $\alpha=0.05$
```{r}
eco_sum <- dbGetQuery(con, "SELECT opening_eco, COUNT(*) as sum FROM chess WHERE opening_eco is not null GROUP BY opening_eco") 
eco_sum = eco_sum[order(-eco_sum[,"sum"]), ]
barplot(eco_sum$sum, xlab="kod ECO", ylab = "liczba gier", names.arg=eco_sum$opening_eco)
print(gpd.test(eco_sum$sum)$boot.test)
#ptsuite::pareto_qq_test(eco_sum$sum)
```
Uzyskana p-wartość jest znacząco mniejsza od przyjętego poziomu istotności, co wspiera odrzucenie $H_1$.

```{r}
most_played = length(eco_sum$sum)*0.2
sprintf("%.2f%%", 100*sum(eco_sum$sum[0:most_played])/sum(eco_sum$sum))
```
Pomimo, że rozkład nie jest zgodny z rozkładem Pareta to zgodnie z zasadą Pareta 20% najczęściej rozgrywanych eco stanowi(w przybliżeniu) 80% wszystkich rozgrywanych eco.\newline\newline

\subsection*{Zwycięstwa względem otwarć}
W rozważaniach zostaną użyte gry z otwarciami użytymi co najmniej 50 razy.\newline
Przez gry wygrane będą rozumiane gry wygrane przez gracza białego.\newline
w-liczba zwycięstw\newline
p-liczba niewygranych gier\newline
$H_0$: Rozkład zwycięstw dla każdego eco jest rozkładem $B(n_i, p\_win)$, gdzie\newline
$n_i=w_i+p_i$ ($w_i,p_i$ - analogicznie do w i p dla rozgrywek w których użyto i-tego otwarcia)\newline 
$p\_win=\frac {w} {w + p}$ \newline
$H_1$: Rozkład zwycięstw dla każdego eco jest rozkładem $B(n_i, p_i)$, gdzie p_i może być różbe dla każdego otwarcia\newline
przyjęty poziom istotności: $\alpha=0.05$
```{r}
eco_sum <- dbGetQuery(con, "SELECT opening_eco, COUNT(*) as sum FROM chess WHERE opening_eco is not null GROUP BY opening_eco") 
eco_sum = eco_sum[order(-eco_sum[,"sum"]), ]

eco <- dbGetQuery(con, "SELECT winner, opening_eco, COUNT(*) as count FROM chess WHERE opening_eco is not null GROUP BY opening_eco, winner") 

eco = merge(eco, eco_sum, by="opening_eco")
win_p = sum(eco$count[eco$winner=='white'])/sum(eco_sum$sum)
  
eco = eco[eco$sum>=50,] # co najmniej 50 gier z danym eco
eco$prob = eco$count/eco$sum
eco = eco[eco$winner=='white',]
eco = eco[order(-eco$prob),]
barplot(eco$prob, names.arg=eco$opening_eco, ylab="% wygranych gier", xlab="kod eco")
```
Aby sprawdzić hipotezę dla każdego eco zostanie estymowany przedział wartośći $p_i$ dla przedziału ufności 0.95. Aby $H_0$ była spełniona znajdowanie się w estymowanym przedziale $p_i$ wartości p_win powinno być określone przez rozkład $B(n, 0.95)$.

```{r}
in_interval = 0
for (i in 1:length(eco$count)){
  res = binom.test(eco$count[i], eco$sum[i], p=win_p)
  if(res$conf.int[1] < win_p && win_p < res$conf.int[2]){
    in_interval = in_interval+1;
  }
}
printf("%.2f%% przedzialów p_i zawiera p_win", in_interval/length(eco$count)*100)
p_val = binom.test(in_interval, length(eco$count), 0.95)$p.value
cat("otrzymana p-wartosc: ", p_val)
```
otrzymana z teście p-wartość << $\alpha$, więc $H_0$ zostaje odrzucona.\newline\newline


$H_0$: nie zachodzi korelacja pomiędzy estymatorem szansy wygranej i częstotliością z jaką dane otwarcie jest zagrywane\newline
$H_1$: zachodzi korelacja pomiędzy estymatorem szansy wygranej i częstotliością z jaką dane eco jest zagrywane\newline
przyjęty poziom istotności: $\alpha=0.05$
```{r}
barplot(rev(eco$count), names.arg=round(100*rev(eco$prob), digits=0), ylab="liczba gier", xlab="% wygranch")
printf("otrzymana p-wartość: %.2f", cor.test(eco$prob, eco$sum)$p.value)
```

Orzymana w teście p-wartość jest większa niż $\alpha$, a wartość korelacji jest bliska 0. Nie ma więc wystarczających dowodów aby odrzucić $H_0$\newline